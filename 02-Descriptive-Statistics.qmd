# Deskriptive Statistik

## Data Frames (Tibbles)

In R werden wir die Daten in Form von Tabellen verwenden, die Variablen (Spalten) enthalten, die die Merkmale der Beobachtungen (Zeilen) beschreiben. Die meisten der Zeit werden wir `tibble`-Objekte verwenden, um die Daten zu halten.

```{r}
if (!requireNamespace("tidyverse", quietly = TRUE)) {
  install.packages("tidyverse")
}

library(tidyverse)
library(readxl)
```

In a limited number of cases we need to construct tables by hand. You can find out more about `tibble` [here](https://tibble.tidyverse.org/articles/tibble.html).

In einigen Anwendungen ist es nützlich, Tabellen manuell zu erstellen. Sie können mehr über
`tibble` [hier](https://tibble.tidyverse.org/articles/tibble.html) erfahren.

```{r}
# Wir erstellen eine Tabelle mit den Daten von fünf Personen
dt <- tibble(
  ## Kurzschreibweise für die Erstellung einer Sequenz von Ganzzahlen von eins bis fünf
  id = 1:5,
  name = c("Alice", "Bob", "Charlie", "David", "Eve"),
  billableHours = c(2, 2.5, 3, 8, 12)
)

# Wir zeigen die Tabelle an
dt
```


In den meisten Fällen werden wir externe Datenquellen wie Textdateien im CSV-Format verwenden. Für diesen Kurs werden die Daten immer in einem Starter-Code-Schnipsel importiert.

The dataset `bikes` contains hourly usage data of shared bikes in London between 2015 and 2017.

Der Datensatz `bikes` enthält stündliche Nutzungsdaten von Fahrrädern in London zwischen 2015 und 2017. Er hat die folgenden Variablen (Spalten):

-   `timestamp` - Die Zeit, zu der die Daten aufgezeichnet wurden (Anfang der Stunde)
-   `cnt` - Die Anzahl der neuen Fahrradvermietungen in dieser Stunde
-   `t1` - Temperatur in Grad Fahrenheit
-   `t2` - Temperatur in Grad Fahrenheit (gefühlte Temperatur)
-   `hum` - Luftfeuchtigkeit in Prozent
-   `wind_speed` - Windgeschwindigkeit in Meilen pro Stunde
-   `weather_code` - Wettercode (kategorische Variable)
-   `is_holiday` - Indikator für Feiertage
-   `is_weekend` - Indikator für Wochenenden
-   `season` - Jahreszeiten: 0-Frühling; 1-Sommer; 2-Herbst; 3-Winter


```{r}
# Download and import the raw data from a CSV file
bikes <- read_csv("https://github.com/febse/data/raw/refs/heads/main/econ/bike_sharing_london_merged.xls") %>%
  mutate(
    t1 = (t1 * 1.8) + 32,
    t2 = (t2 * 1.8) + 32,
    wind_speed = wind_speed * 1.60934
  )

# Print the first few lines
bikes %>% head()
```

## Neue Variablen erstellen

Before we start summarizing the data, we will convert some of the variables to more familiar units: temperature from Fahrenheit to Celsius, wind speed from miles per hour h to m/h.

Als Übung werden wir die zwei Temperaturvariablen `t1` und `t2` von Fahrenheit in Celsius umwandeln. Die Formel zur Umrechnung von Fahrenheit in Celsius lautet:

$$
\text{Degree Celsius} = \frac{\text{Degree Fahrenheit} - 32}{1.8}
$$

```{r}
bikes %>%
  mutate(
    temp_c = (t1 - 32) / 1.8
  )
```

Beachten Sie, daß das Objekt, das die ursprünglichen Daten enthält, durch `mutate` nicht verändert wird. Der Grund dafür ist, dass Funktionen in R im Allgemeinen ihre Argumente nicht ändern. Wenn Sie die beiden neuen Spalten dem ursprünglichen Datensatz `bikes` hinzufügen möchten, müssen Sie ihn mit einer Zuweisung überschreiben.

```{r}
bikes <- bikes %>%
  mutate(
    temp_c = (t1 - 32) / 1.8
  )
```

::: {#exr-mutate}
## Mutate

Create a new column in the `bikes` dataset called `temp_felt_c` that contains the feels like temperature in Celsius. Also create a new column called `wind_speed_kmh` that contains the wind speed in kilometers per hour. **Hint**: Use the `mutate` function and assign the result back to the `bikes` object.

```{r}
# Write your code here

```
:::

## Datenüberblick

The first step in any data analysis is to gain an initial understanding of the context of the data and the distributions of the variables of interest. In this course our main focus will be on two features of the variables: their location and their variability (how different are the observations between each other). In addition, an initial screening of is helpful to identify potential problems in the data:

-   Extremely unusual values (outliers)
-   Missing values
-   Logical inconsistencies in the data

It is especially important to detect these problems in the early stages of the analysis.

Der esrte Schritt in jeder Datenanalyse besteht darin, ein erstes Verständnis des Kontexts der Daten und der Verteilungen der interessierenden Variablen zu gewinnen. In diesem Kurs werden wir uns hauptsächlich auf zwei Merkmale der Variaben konzentrieren: ihre Lokation und ihre Variabilität (wie unterschiedlich sind die Beobachtungen untereinander). Darüber hinaus ist ein erster Screening hilfreich, um potenzielle Probleme in den Daten zu identifizieren:

### Lokation (Mittelpunkt)

The most important measure of location for us will be the empirical mean of a variable (arithmetic average). Let $i$ index the observation in our data set from the first ($i = 1$) to the last $i = n$. In our case $n = 1816$: the number of all interviewed customers. We can represent the values of some (numeric) characteristic (e.g., the persons' weight) as a vector of values $x = (x_1, \ldots, x_n)$. In this notation $x_1$ is the weight of the first customer in the data set ($x_1 = 210$ pounds). The arithmetic average is defined as the sum of all values divided by the number of observations:

Die wichtigste Maßzahl für die Lokation wird für uns der empirische Mittelwert einer Variablen (arithmetisches Mittel) sein. Lassen Sie $i$ die Beobachtung in unserem Datensatz vom ersten ($i = 1$) bis zum letzten $i = n$ indizieren. In unserem Fall $n = 1816$: die Anzahl aller befragten Kunden. Wir können die Werte einer (numerischen) Eigenschaft (z.B. das Gewicht der Personen) als Vektor von Werten $x = (x_1, \ldots, x_n)$ darstellen. In dieser Notation ist $x_1$ das Gewicht des ersten Kunden im Datensatz ($x_1 = 210$ Pfund). Der arithmetische Durchschnitt ist definiert als die Summe aller Werte geteilt durch die Anzahl der Beobachtungen:

$$
\bar{x} = \frac{1}{n}(x_1 + x_2 + \ldots + x_n) = \frac{1}{n}\sum_{i = 1}^{n} x_i
$$


Lassen Sie uns nun den arithmetischen Durchschnitt von `cnt` berechnent.

```{r}
mean(bikes$cnt)
```

Eine andere Maßzahl für die Lokation ist der (empirische) Median. Sie können ihn mit der Funktion `median` berechnen.

```{r}
median(bikes$cnt)
```

::: {#exr-location}
## Lokation (Mittelwert und Median)

Berechnen Sie den arithmetischen Durchschnitt und den Median der Temperatur (`temp_c`). Wie interpretieren Sie diese Werte?

```{r}
# Schreiben Sie Ihren Code hier

```
:::


Andere Maßzahlen für die Lokation sind der Modus (der häufigste Wert) und die Quantile. Im Allgemeinen macht der Modus nur für kategoriale Variablen Sinn.

```{r}
min(bikes$cnt)
max(bikes$cnt)

# It is very common to divide the data into four parts (quartiles) to get a better understanding of the distribution of the data.
quantile(bikes$cnt, probs = c(0, 0.25, 0.5, 0.75, 1))
```

The first quartile of `cnt` (25-th percentile and 0.25 quantile are different names for the same thing) is the number of bike rentals per hour such that about 25 percent (one quarter) of the hours had fewer rentals.

Das erste Quantil von `cnt` (25-tes Perzentil und 0,25 Quantil sind unterschiedliche Namen für dasselbe) ist die Anzahl der Fahrradvermietungen pro Stunde, so dass etwa 25 Prozent (ein Viertel) der Stunden weniger Vermietungen hatten. 

```{r}
quantile(bikes$cnt, 0.25)

```

```{r}
mean(bikes$cnt < 257)
```

Das zweite Quartil ist das gleiche wie der Median (zwei Viertel).

```{r}
quantile(bikes$cnt, 0.5)
median(bikes$cnt)
mean(bikes$cnt < median(bikes$cnt))
```

Das dritte Quartil ist die Anzahl der stündlichen Vermietungen, so dass etwa 75 Prozent der Stunden weniger Vermietungen hatten (und etwa 25 Prozent mehr Vermietungen hatten).

```{r}
quantile(bikes$cnt, 0.75)
mean(bikes$cnt < quantile(bikes$cnt, 0.75))
mean(bikes$cnt > quantile(bikes$cnt, 0.75))
```

::: {#exr-location-quantiles}
## Minimum, Maximum, und Quartile

Compute the minimum, maximum, and the quartiles of the `temp_c` variable. How do you interpret these values? Compute the proportion of hours with a temperature:

-   Below the first quartile
-   Above the median
-   Above the third quartile.
-   Between the first and the third quartile.
-   Between the median and the third quartile.
-   Between the median and the first quartile.

Berechnen Sie das Minimum, Maximum und die Quartile der Variablen `temp_c`. Wie interpretieren Sie diese Werte? Berechnen Sie den Anteil der Stunden mit einer Temperatur:

-   Unter dem ersten Quartil
-   Über dem Median
-   Über dem dritten Quartil.
-   Zwischen dem ersten und dem dritten Quartil.
-   Zwischen dem Median und dem dritten Quartil.


```{r}
# Write your code here

```
:::

### Variabilität

The next important feature of the data is its variability. It answers the following question: how different were the hours in the data with respect to the number of rented bikes. There are numerous ways to measure variability. To illustrate this, let us consider look at the boxplot of the `cnt` variable by `season`.

A boxplot is a graphical representation of the distribution of the data that uses the quartiles to show the location and the spread of the data. The boxplot shows the median (the second quartile), the first and the third quartile (the 25-th and the 75-th percentile), and the whiskers that extend to the most extreme data points that are not considered outliers. Outliers are shown as individual points.

Der nächste wichtige Aspekt der Daten ist ihre Variabilität. Es beantwortet die Frage: Wie unterschiedlich waren die Stunden in den Daten hinsichtlich der Anzahl der vermieteten Fahrräder. Es gibt zahlreiche Möglichkeiten, die Variabilität zu messen. Um dies zu veranschaulichen, betrachten wir den Boxplot der Variablen `cnt` nach `season`.

```{r}
bikes %>%
  ggplot(aes(y = factor(season), x = cnt)) +
  geom_boxplot()
```


One intuitive measure would be the range of the data, defined as the difference between the maximum and the minimum value.

Eine intuitive Maßzahl wäre der Bereich der Daten, definiert als die Differenz zwischen dem maximalen und dem minimalen Wert.

```{r}
max(bikes$cnt)
min(bikes$cnt)
max(bikes$cnt) - min(bikes$cnt)

range(bikes$cnt)
```


Eine andere Maßzahl ist der Interquartilbereich, der die Differenz zwischen dem dritten und dem ersten Quartil ist.

```{r}
quantile(bikes$cnt, 0.75) - quantile(bikes$cnt, 0.25)
```

Wie der Bereich ist der Interquartilbereich ein Maß für die Variabilität, jedoch ist er viel weniger empfindlich gegenüber extremen Werten.

::: {#def-empirical-variance}
## Empirische Varianz

For a vector of values $x = (x_1, \ldots, x_n)$ it is defined as the average (apart from a small correction in the denominator) squared deviation of the values from their mean.

Für einen Vektor von Werten $x = (x_1, \ldots, x_n)$ ist sie definiert als der Durchschnitt (abgesehen von einer kleinen Korrektur im Nenner) der quadrierten Abweichungen der Werte von ihrem Mittelwert.

$$
S^2_x = \frac{(x_1 - \bar{x})^2 + \ldots + (x_n - \bar{x})^2}{n - 1} = \frac{1}{n - 1} \sum_{i = 1}^{n}(x_i - \bar{x})^2: \quad \text{variance}\\
S_x = \sqrt{S^2_x} \quad \text{standard deviation}
$$
:::

::: {#exm-empirical-variance}
## Berechnung der empirischen Varianz

Lassen Sie uns die Formel aus @def-empirical-variance auf ein sehr einfaches Beispiel mit nur drei Werten anwenden.

$$
x_1 = -1, x_2 = 0, x_3 = 4
$$

Zuerst ist der empirische Mittelwert dieser Werte

$$
\bar{x} = \frac{-1 + 0 + 4}{3} = 1
$$

Jetzt setzen wir diese Werte in die Definition der empirischen Varianz ein:

$$
\begin{aligned}
S^2_{x} & = \frac{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2 + (x_3 - \bar{x})^2 }{n - 1} \\
        & = \frac{(-1 - 1)^2 + (0 - 1)^2 + (4 - 1)^2 }{3 - 1} \\
        & = \frac{(-2)^2 + (- 1)^2 + (3 )^2 }{2} \\
        & = \frac{4 + 1 + 9 }{2} \\
        & = \frac{14}{2} \\
        & = 7
\end{aligned}
$$

Vergleichen wir unser Ergebnis mit der Berechnung in R.

```{r}
# Ein Vektor mit drei Werten
x <- c(-1, 0, 4)
# Berechnen des Mittelwerts von x

x_avg <- mean(x)

# Hier berechnen wir die Summe der quadrierten Abweichungen von x_avg

((-1 - x_avg)^2 + (0 - x_avg)^2 + (4 - x_avg)^2) / (length(x) - 1)
```

```{r}
# Oder mit der sum Funktion
sum((x - mean(x))^2) / (length(x) - 1)
```

Es gibt auch eine spezielle Funktion namens `var`, die sie aus einem Vektor berechnen kann.

```{r}
var(x)
```

Die (empirische) Standardabweichung ist einfach die Quadratwurzel der (empirischen) Varianz.

$$
S_x = \sqrt{S^2_x} = \sqrt{7} \approx 2.64 
$$


```{r}
sqrt(var(x))
sd(x)
```
:::

::: callout-note
## Interpretation der Standardabweichung

Die Standardabweichung ist ein Maß für die Streuung der Daten. Es ist der durchschnittliche Abstand der Beobachtungen vom Mittelwert.

```{r}
x1 <- c(-1, 0, 1)
var(x)
sd(x)
```

```{r}
x2 <- c(-2, 0, 2)
var(x)
sd(x)
```

```{r}
x3 <- c(-2, -1, 0, 1, 2)
var(x)
sd(x)
```
:::

Lassen Sie uns die empirischen Standardabweichungen von `cnt` nach `season` berechnen. Wir werden diese Gelegenheit nutzen, um die Funktion `group_by` aus dem Paket `dplyr` vorzustellen. Diese Funktion ermöglicht es uns, die Daten nach einer Variablen zu gruppieren und dann eine Funktion auf jede Gruppe anzuwenden.

```{r}
bikes %>%
  group_by(season) %>%
  summarize(
    mean_cnt = mean(cnt),
    sd_cnt = sd(cnt)
  )
```

::: {#exr-empirical-moments}
## Empirische Momente (Mittelwert, Varianz und Standardabweichung)

1. Berechnen Sie den Mittelwert und die Varianz der Variablen `temp_c` im Datensatz `bikes`. Wie interpretieren Sie diese Werte?

```{r}
# Schreiben Sie Ihren Code hier

```

2.  Use the `summarize` function from the `dplyr` (already loaded) package to compute the mean and the variance of the `temp_c` variable.

```{r}
# Schreiben Sie Ihren Code hier

```

3.  Run the same calculations as before, but this time group the dataset by the `ethnicity` variable. This will give you the mean and the variance of the annual earnings for every ethnic group in the data set. Use the `group_by` function.

```{r}
# Schreiben Sie Ihren Code hier

```
:::

### Data Overview

The `skim` function from the `skimr` package provides a quick overview of the data set. It shows the number of observations, the number of variables, the names of the variables, the type of the variables, the number of missing values, the mean, the standard deviation, the minimum and maximum values, and the quartiles for the numeric variables.

```{r}
## Basic summaries for the whole tibble
bikes %>% skimr::skim()
```

### Summarizing a single categorical variable

While the mean, median, and variance are useful for numeric variables, they are not defined for categorical variables. Instead, we can use the `table` function to count the number of observations in each category.

```{r}
table(bikes$season)
```

## Visualizations

Histogram

```{r}
bikes %>%
  ggplot(aes(x = cnt)) +
  geom_histogram()
```

A smooth density plot is an alternative way to visualize the distribution of a variable.

```{r}
bikes %>%
  ggplot(aes(x = cnt)) +
  geom_density()
```

The boxplot shows the median and the 25-th and 75-th percentiles (the box). The whiskers in the plot stretch to the minimum or the maximum observed value, unless there are extreme observations that are shown as single dots.

The scatterplot will be our primary tool in studying associations between variables. It represents each observation as a point in a coordinate system defined by the variables that we would like to study.

```{r}
bikes %>%
  ggplot(aes(x = temp_c, y = cnt)) +
  geom_point(position = "jitter", alpha = 0.2) +
  labs(
    x = "Temperature (C)",
    y = "Number of rentals"
  )
```

```{r}
summary(lm(cnt ~ temp_c, data = bikes))
```

::: {#exr-descriptive-statistics}
The `earnings` dataset contains the result from a survey of mall customers. The dataset contains the following variables:

-   `height` - the height of the customer in inches
-   `weight` - the weight of the customer in pounds
-   `male` - a binary variable indicating a male (1) customer or a female (0) customer
-   `earn` - the annual earnings of the customer in dollars
-   `earnk` - the annual earnings of the customer in thousands of dollars
-   `ethnicity` - A categorical variable indicating the ethnicity of the customer (White, Black, Hispanic, Other)
-   `education` - The number of years of education of the customer
-   `mother_education` - The number of years of education of the customer's mother

```{r}
earnings <- read_csv("https://github.com/febse/data/raw/refs/heads/main/econ/earnings.csv") %>% 
  mutate(
   male = as.factor(male)
  )
earnings %>% head()
```

-   Create a new variable `bmi` (body mass index) in the `earnings` data set. The BMI is defined as the weight in kilograms divided by the square of the height in meters. The height in meters is the height in centimeters divided by 100. To facilitate the computation, convert the height from inches to centimeters and the weight from pounds to kilograms and store these values in new variables `height_cm` and `weight_kg`.

$$
\text{BMI} = \frac{\text{weight (kg)}}{(\text{height (cm)} / 100)^2}
$$

-   Compute the quartiles of the `bmi` variable. How do you interpret these values?

```{r}
# Write your code here

```

-   Visualize the distribution of the `bmi` variable by sex (use the `male`). What can you say about the distributions of the BMI between men and women?

```{r}
# Write your code here

```

-   The reference ranges for the BMI are as follows:

-   Under 18,5: Underweight

-   18,5 - 24,9: Normal

-   25 - 29,9: Overweight

-   30 oder mehr: Obese

Create two new variables `is_underweight`, `is_normal` in the dataset. *Hint*: Use the `mutate` function and the `<`, `<=`, `>`, `>=` operators. You can join multiple conditions using the `&` (logical and) operator. Don't forget to uncomment the code first (Ctrl+Shift+C). How many customers are underweight and how many have a normal weight? Use the `summarize` function to compute the number of customers in each category.

```{r}
# Write your code here

```

-   Group the data by `male` and compute the number of customers in each group, as well as the number of underweight and normal weight customers in each group. Additionally, compute the share of underweight and normal weight customers in each group. *Hint*: Use the `group_by` function and the `summarize` function. Don't forget to uncommend the code first (Ctrl+Shift+C). The `n()` function can be used to compute the number of observations in each group.

```{r}
# Write your code here

```
:::